---
title: "GAMMs analyses Trombone - Notes vs. vowels (NZE and Tongan)"
author:
  - Jalal Al-Tamimi (Newcastle University)
  - Donald Derrick (University of Canterbury)
  - Matthias Heyne (Boston University)
date: "`r format(Sys.time(), '%d %B %Y')`"
output:
  html_notebook:
    number_sections: yes
    toc: yes
    toc_depth: 6
    toc_float:
      collapsed: yes
  html_document:
    toc: yes
    toc_depth: '6'
---

This notebook provides the second half of the full analysis of the article: Heyne, M., Derrick, D., and Al-Tamimi, J. (under review). "Native language influence on brass instrument performance: An application of generalized additive mixed models (GAMMs) to midsagittal ultrasound images of the tongue". Frontiers Research Topic: Models and Theories of Speech Production. Ed. Adamantios Gafos & Pascal van Lieshout.

```{r warning=FALSE, message=FALSE, error=FALSE}
# specify directory to save models and summaries
output_dir = "updated_models"

# specify whether to run models -> if set to false script will attempt to load saved models from output_dir
run_models = FALSE
```

# Loading packages

```{r warning=FALSE, message=FALSE, error=FALSE}
load_packages = c("readr","knitr","ggplot2","mgcv","itsadug","parallel","dplyr","rlist","plotly")
# dplyr, rlist, and plotly are required by the custom plotting functions
for(pkg in load_packages){
  eval(bquote(library(.(pkg))))
  if (paste0("package:", pkg) %in% search()){
    cat(paste0("Successfully loaded the ", pkg, " package.\n"))
  }else{
    install.packages(pkg)
    eval(bquote(library(.(pkg))))
    if (paste0("package:", pkg) %in% search()){
      cat(paste0("Successfully loaded the ", pkg, " package.\n"))
    }
  }
}
rm(load_packages, pkg)

# detect number of cores available for model calculations
ncores = detectCores()
cat(paste0("Number of cores available for model calculations set to ", ncores, "."))
```

# Loading custom plotting function

## plotly_scatterpolar_multiplot function (Matthias Heyne, 2019)

```{r warning=FALSE, message=FALSE, error=FALSE}
# save plots by using the option from the html widget created by markdown
# updated 13 April for conflated Tongan vowels
# This function plots multiple smoothing splines in the same window
plotly_scatterpolar_multiplot <- function(df, horizontal, vertical, cols2plot, print=TRUE){
  if (length(cols2plot)>2){
    print("ERROR: You specified more than 2 columns of values to plot.")
  }else{
    dat1=df
    df_name=deparse(substitute(df))
    # layout option 1
    if (length(horizontal)==2 & length(vertical)==1){
      # Note, Intensity, Language
      hori1=nrow(unique(select(dat1, horizontal[1])))
      hori2=nrow(unique(select(dat1, horizontal[2])))
      hori=hori1*hori2
      vert=nrow(unique(select(dat1, vertical[1])))
      dat1=select(dat1, c(horizontal[1],horizontal[2],vertical[1],cols2plot[1],cols2plot[2]))
      dat1=droplevels(dat1)
      var_hori1=levels(dat1[,1])
      var_hori2=levels(dat1[,2])
      var_vert1=levels(dat1[,3])
      
      # set up line types & colors
      ltypes=list("","dash") # match length of hori1
      colors=list("blue","green","orange","red") # match length of hori2
      cat(paste0("Proceeding to assemble a ", hori, "x", vert, " multiplot.\n"))
      cat(paste0("Your plot will show the columns/variables ",horizontal[1]," & ",horizontal[2]," in the horizontal direction and ",vertical[1]," in the vertical direction.\n"))
      cat(paste0(horizontal[1], " will be plotted using the following linestyles: -> "))
      for (n in 1:length(var_hori1)){
        if (n<length(var_hori1)){
          cat(paste0(var_hori1[n], ": ", ltypes[n], " - "))
        }else{
          cat(paste0(var_hori1[n], ": ", ltypes[n], "\n"))
        }
      }
      cat(paste0(horizontal[2], " will be plotted using the following colors: -> "))
      for (n in 1:length(var_hori2)){
        if (n<length(var_hori2)){
          cat(paste0(var_hori2[n], ": ", colors[n], " - "))
        }else{
          cat(paste0(var_hori2[n], ": ", colors[n], "\n"))
        }
      }
      rm(n)
      cat(paste0(vertical[1], " will be shown in the vertical direction from ", var_vert1[1], " (bottom) to ", var_vert1[length(var_vert1)], " (top).\n"))

      # assemble layout options for all subplots
      # plot_specs set as default
      plot_specs = list(sector=c(20,160), radialaxis=list(angle=90, range=c(0,max(dat1$rho_uncut_z)), tickfont=list(size=2)), 
                        angularaxis=list(thetaunit='radians', direction="clockwise", rotation=0, tickfont=list(size=4)))
      # set layout options for required number of subplots
      for (i in 1:hori){
        for (j in 1:vert){
          specsX=list.append(plot_specs, domain=list(x=c((i-1)/hori+(1/hori*0.2), i/hori-1/hori*0.2), 
                                                     y=c((j-1)/vert+(1/vert*0.1),j/vert-1/vert*0.1)))
          assign(paste0("sub_plot",((j-1)*hori)+i), specsX)
        }
      }
      rm(i, j, specsX)
      
      # assemble smoothing splines for traces
      for (j in 1:vert){
        # subset data set by vertical
        dat2=dat1[dat1[,3]==var_vert1[j],]
        for (i1 in 1:hori1){
          # subset data set by horizontal[1]
          dat3=dat2[dat2[,1]==var_hori1[i1],]
          for (i2 in 1:hori2){
            # subset data set by horizontal[2]
            dat4=dat3[dat3[,2]==var_hori2[i2],]
            if (!nrow(dat4)==0){
              if ((((j-1)*hori)+((i1-1)*hori2)+i2)==1){
                # assemble trace & assign number
                traceX=list(theta=seq(min(dat4$theta_uncut_z)*180/pi,max(dat4$theta_uncut_z)*180/pi, length=100), 
                            r=predict(smooth.spline(dat4$theta_uncut_z, dat4$rho_uncut_z),
                                      seq(min(dat4$theta_uncut_z),max(dat4$theta_uncut_z), length=100))$y,
                            line=list(color=colors[i2], dash=ltypes[i1]))
                assign(paste0("trace",((j-1)*hori)+((i1-1)*hori2)+i2),traceX)
              }else if ((((j-1)*hori)+((i1-1)*hori2)+i2)<=hori){
                # assemble trace & assign number
                traceX=list(theta=seq(min(dat4$theta_uncut_z)*180/pi,max(dat4$theta_uncut_z)*180/pi, length=100), 
                            r=predict(smooth.spline(dat4$theta_uncut_z, dat4$rho_uncut_z),
                                      seq(min(dat4$theta_uncut_z),max(dat4$theta_uncut_z), length=100))$y,
                            line=list(color=colors[i2], dash=ltypes[i1]), subplot=paste0("polar",((j-1)*hori)+((i1-1)*hori2)+i2))
                assign(paste0("trace",((j-1)*hori)+((i1-1)*hori2)+i2),traceX)
              }else{
                # assemble trace & assign number
                traceX=list(theta=seq(min(dat4$theta_uncut_z)*180/pi,max(dat4$theta_uncut_z)*180/pi, length=100), 
                            r=predict(smooth.spline(dat4$theta_uncut_z, dat4$rho_uncut_z),
                                      seq(min(dat4$theta_uncut_z),max(dat4$theta_uncut_z), length=100))$y,
                            line=list(color=colors[i2], dash=ltypes[i1]), subplot=paste0("polar",((j-1)*hori)+((i1-1)*hori2)+i2), showlegend=FALSE)
                assign(paste0("trace",((j-1)*hori)+((i1-1)*hori2)+i2),traceX)
            }
            }
            }
        }
      }
      rm(j, i1, i2, traceX, dat2, dat3, dat4)

      # plot assembled traces with assembed layout specifications
      p = plot_ly(type='scatterpolar', mode='lines')
      dont_plot=c()
      p = add_trace(p, theta=trace1$theta, r=trace1$r, line=list(color=trace1$line$color[[1]], dash=trace1$line$dash[[1]]))
      for (k in 2:(hori*vert)){
        if (exists(paste0("trace",k))){
          p = add_trace(p, theta=get(paste0("trace",k))$theta, r=get(paste0("trace",k))$r, 
                        subplot=get(paste0("trace",k))$subplot, 
                        line=list(color=get(paste0("trace",k))$line$color[[1]], dash=get(paste0("trace",k))$line$dash[[1]]))
        }else{
          dont_plot=c(dont_plot,k)
        }
      }
      
      # set layout
      layout_comp = capture.output(
        for (l in 1:(hori*vert)){
          if (is.na(match(l, dont_plot))){
            if (l==1){
              cat(paste0("layout(p, polar=sub_plot",l,", "))
            }else if (l<=hori){
              cat(paste0("polar",l,"=sub_plot",l,", "))
            }else if (l<hori*vert){
              cat(paste0("polar",l,"=sub_plot",l,", "))
            }else{
              cat(paste0("polar",l,"=sub_plot",l,", showlegend=FALSE)"))
            }
          }
        })
      p; eval(parse(text=layout_comp))
      
    # layout option 2
    }else if (length(horizontal)==1 & length(vertical)==2){
      # Subject, Note, Intensity
      hori=nrow(unique(select(dat1, horizontal[1])))
      vert1=nrow(unique(select(dat1, vertical[1])))
      vert2=nrow(unique(select(dat1, vertical[2])))
      vert=vert1*vert2
      dat1=select(dat1, c(horizontal[1],vertical[1],vertical[2],cols2plot[1],cols2plot[2]))
      # dat1[,1]=horizontal[1]; dat1[,2]=horizontal[2]; dat1[,3]=vertical[1];
      dat1=droplevels(dat1)
      var_hori1=levels(dat1[,1])
      var_vert1=levels(dat1[,2])
      var_vert2=levels(dat1[,3])
      
      # set up line types & colors
      colors=list("blue","green","orange","red","gray") # match length of vert1
      ltypes=list("","dash","dashdot","dot") # match length of vert2
      cat(paste0("Proceeding to assemble a ", hori, "x", vert, " multiplot.\n"))
      cat(paste0("Your plot will show the columns/variables ",vertical[1]," & ",vertical[2]," in the vertical direction and ",horizontal[1]," in the horizontal direction.\n"))
      cat(paste0(vertical[1], " will be plotted using the following colors: -> "))
      for (n in 1:length(var_vert1)){
        if (n<length(var_vert1)){
          cat(paste0(var_vert1[n], ": ", colors[n], " - "))
        }else{
          cat(paste0(var_vert1[n], ": ", colors[n], "\n"))
        }
      }
      cat(paste0(vertical[2], " will be plotted using the following linestyles: -> "))
      for (n in 1:length(var_vert2)){
        if (n<length(var_vert2)){
          cat(paste0(var_vert2[n], ": ", ltypes[n], " - "))
        }else{
          cat(paste0(var_vert2[n], ": ", ltypes[n], "\n"))
        }
      }
      rm(n)
      cat(paste0(horizontal[1], " will be shown in the horizontal direction from ", var_hori1[1], " (left) to ", var_hori1[length(var_hori1)], " (right).\n"))

      # assemble layout options for all subplots
      # plot_specs set as default
      plot_specs = list(sector=c(20,160), radialaxis=list(angle=90, range=c(0,max(dat1$rho_uncut_z)), tickfont=list(size=2)), 
                        angularaxis=list(thetaunit='radians', direction="clockwise", rotation=0, tickfont=list(size=4)))
      # set layout options for required number of subplots
      for (i in 1:hori){
        for (j in 1:vert){
          specsX=list.append(plot_specs, domain=list(x=c((i-1)/hori+(1/hori*0.2), i/hori-1/hori*0.2), 
                                                     y=c((j-1)/vert+(1/vert*0.1),j/vert-1/vert*0.1)))
          assign(paste0("sub_plot",((j-1)*hori)+i), specsX)
        }
      }
      rm(i, j, specsX)
      
      # assemble smoothing splines for traces
      for (i in 1:hori){
        # subset data set by horizontal
        dat2=dat1[dat1[,1]==var_hori1[i],]
        for (j1 in 1:vert1){
          # subset data set by vertical[1]
          dat3=dat2[dat2[,2]==var_vert1[j1],]
          for (j2 in 1:vert2){
            # subset data set by vertical[2]
            dat4=dat3[dat3[,3]==var_vert2[j2],]
            if (!nrow(dat4)==0){
              if (i+((j1-1)*vert)+((j2-1)*hori)+((j1-1)*vert)==1){
                # assemble trace & assign number
                traceX=list(theta=seq(min(dat4$theta_uncut_z)*180/pi,max(dat4$theta_uncut_z)*180/pi, length=100), 
                            r=predict(smooth.spline(dat4$theta_uncut_z, dat4$rho_uncut_z),
                                      seq(min(dat4$theta_uncut_z),max(dat4$theta_uncut_z), length=100))$y,
                            line=list(color=colors[j1], dash=ltypes[j2]))
                assign(paste0("trace", i+((j1-1)*vert)+((j2-1)*hori)+((j1-1)*vert)), traceX)
              }else if (i+((j1-1)*vert)+((j2-1)*hori)+((j1-1)*vert)<=hori){
                # assemble trace & assign number
                traceX=list(theta=seq(min(dat4$theta_uncut_z)*180/pi,max(dat4$theta_uncut_z)*180/pi, length=100), 
                            r=predict(smooth.spline(dat4$theta_uncut_z, dat4$rho_uncut_z),
                                      seq(min(dat4$theta_uncut_z),max(dat4$theta_uncut_z), length=100))$y,
                            line=list(color=colors[j1], dash=ltypes[j2]), subplot=paste0("polar",i+((j1-1)*vert)+((j2-1)*hori)+((j1-1)*vert)))
                assign(paste0("trace",i+((j1-1)*vert)+((j2-1)*hori)+((j1-1)*vert)),traceX)
              }else{
                # assemble trace & assign number
                traceX=list(theta=seq(min(dat4$theta_uncut_z)*180/pi,max(dat4$theta_uncut_z)*180/pi, length=100), 
                            r=predict(smooth.spline(dat4$theta_uncut_z, dat4$rho_uncut_z),
                                      seq(min(dat4$theta_uncut_z),max(dat4$theta_uncut_z), length=100))$y,
                            line=list(color=colors[j1], dash=ltypes[j2]), subplot=paste0("polar",i+((j1-1)*vert)+((j2-1)*hori)+((j1-1)*vert)), showlegend=FALSE)
                assign(paste0("trace",i+((j1-1)*vert)+((j2-1)*hori)+((j1-1)*vert)),traceX)
              }
            }
          }
        }
      }
      rm(i, j1, j2, traceX, dat2, dat3, dat4)
      
      # plot assembled traces with assembed layout specifications
      p = plot_ly(type='scatterpolar', mode='lines')
      dont_plot=c()
      p = add_trace(p, theta=trace1$theta, r=trace1$r, line=list(color=trace1$line$color[[1]], dash=trace1$line$dash[[1]]))
      for (k in 2:(hori*vert)){
        if (exists(paste0("trace",k))){
          p = add_trace(p, theta=get(paste0("trace",k))$theta, r=get(paste0("trace",k))$r, 
                        subplot=get(paste0("trace",k))$subplot, 
                        line=list(color=get(paste0("trace",k))$line$color[[1]], dash=get(paste0("trace",k))$line$dash[[1]]))
        }else{
          dont_plot=c(dont_plot,k)
        }
      }

      # set layout
      layout_comp = capture.output(
        for (l in 1:(hori*vert)){
          if (is.na(match(l, dont_plot))){
            if (l==1){
              cat(paste0("layout(p, polar=sub_plot",l,", "))
            }else if (l<=hori){
              cat(paste0("polar",l,"=sub_plot",l,", "))
            }else if (l<hori*vert){
              cat(paste0("polar",l,"=sub_plot",l,", "))
            }else{
              cat(paste0("polar",l,"=sub_plot",l,", showlegend=FALSE)"))
            }
          }
        })
      p; eval(parse(text=layout_comp))
      
    # layout option 3
    }else if (length(horizontal)==1 & length(vertical)==1){
      # Subject, tokenPooled
      hori=nrow(unique(select(dat1, horizontal[1])))
      vert=nrow(unique(select(dat1, vertical[1])))
      dat1=select(dat1, c(horizontal[1],vertical[1],cols2plot[1],cols2plot[2]))
      dat1=droplevels(dat1)
      var_hori1=levels(dat1[,1])
      var_vert1=levels(dat1[,2])
        
      # set up line types & colors
      if (unique(df$native_lg=="Tongan")){
        # levels(dfTongan$token)
        colors=list("#D50D0B","#D50D0B","#003380","#003380","#FF7B00","#FF7B00","#009737","#009737","#C20088","#C20088","#191919","#191919","#191919","#191919","#191919")
        ltypes=list("","dash","","dash","","dash","","dash","","dash","","dash","dashdot","dot","dash")
      }else if (unique(df$native_lg=="NZE")){
        # levels(dfNZE$token)
        colors=list("#D50D0B","#990000","#0075DC","#E082B4","#003380","#FF7B00","#009737","#00AFC3","#C20088","#8F48B7","#ACB500","#7B4937","#6C6C6C","#191919","#191919","#191919","#191919","#191919")
        ltypes=list("","","","","","","","","","","","","","","dash","dashdot","dot","dash")
      }
      cat(paste0("Proceeding to assemble a ", hori, "x", vert, " multiplot.\n"))
      cat(paste0("Your plot will show the columns/variables ",horizontal[1]," in the horizontal direction and ",vertical[1]," in the vertical direction.\n"))
      cat(paste0(vertical[1], " will be shown in the vertical direction from ", var_vert1[1], " (bottom) to ", var_vert1[length(var_vert1)], " (top).\n"))
      
      # assemble layout options for all subplots
      # plot_specs set as default
      plot_specs = list(sector=c(20,160), radialaxis=list(angle=90, range=c(0,max(dat1$rho_uncut_z)), tickfont=list(size=2)), 
                        angularaxis=list(thetaunit='radians', direction="clockwise", rotation=0, tickfont=list(size=4)))
      # set layout options for required number of subplots
      for (i in 1:hori){
        for (j in 1:vert){
          specsX=list.append(plot_specs, domain=list(x=c((i-1)/hori+(1/hori*0.2), i/hori-1/hori*0.2), 
                                                     y=c((j-1)/vert+(1/vert*0.1),j/vert-1/vert*0.1)))
          assign(paste0("sub_plot",((j-1)*hori)+i), specsX)
        }
      }
      rm(i, j, specsX)
      
      # assemble smoothing splines for traces
      for (i in 1:hori){
        # subset data set by horizontal
        dat2=dat1[dat1[,1]==var_hori1[i],]
        for (j in 1:vert){
          # subset data set by vertical[1]
          dat3=dat2[dat2[,2]==var_vert1[j],]
          if (!nrow(dat3)==0){
            if (i+(j-1)*hori==1){
              # assemble trace & assign number
              traceX=list(theta=seq(min(dat3$theta_uncut_z)*180/pi,max(dat3$theta_uncut_z)*180/pi, length=100), 
                          r=predict(smooth.spline(dat3$theta_uncut_z, dat3$rho_uncut_z),
                                    seq(min(dat3$theta_uncut_z),max(dat3$theta_uncut_z), length=100))$y,
                          line=list(color=colors[j], dash=ltypes[j]))
              assign(paste0("trace", i+(j-1)*hori), traceX)
            }else if (i+(j-1)*hori<=hori){
              # assemble trace & assign number
              traceX=list(theta=seq(min(dat3$theta_uncut_z)*180/pi,max(dat3$theta_uncut_z)*180/pi, length=100), 
                            r=predict(smooth.spline(dat3$theta_uncut_z, dat3$rho_uncut_z),
                                      seq(min(dat3$theta_uncut_z),max(dat3$theta_uncut_z), length=100))$y,
                            line=list(color=colors[j], dash=ltypes[j]), subplot=paste0("polar",i+(j-1)*hori))
              assign(paste0("trace", i+(j-1)*hori), traceX)
            }else{
              # assemble trace & assign number
              traceX=list(theta=seq(min(dat3$theta_uncut_z)*180/pi,max(dat3$theta_uncut_z)*180/pi, length=100), 
                          r=predict(smooth.spline(dat3$theta_uncut_z, dat3$rho_uncut_z),
                                    seq(min(dat3$theta_uncut_z),max(dat3$theta_uncut_z), length=100))$y,
                          line=list(color=colors[j], dash=ltypes[j]), subplot=paste0("polar",i+(j-1)*hori), showlegend=FALSE)
              assign(paste0("trace", i+(j-1)*hori), traceX)
            }
          }
        }
      }
      rm(i, j, traceX, dat2, dat3)
      
      # plot assembled traces with assembed layout specifications
      p = plot_ly(type='scatterpolar', mode='lines')
      dont_plot=c()
      p = add_trace(p, theta=trace1$theta, r=trace1$r, line=list(color=trace1$line$color[[1]], dash=trace1$line$dash[[1]]))
      for (k in 2:(hori*vert)){
        if (exists(paste0("trace",k))){
          p = add_trace(p, theta=get(paste0("trace",k))$theta, r=get(paste0("trace",k))$r, 
                        subplot=get(paste0("trace",k))$subplot, 
                        line=list(color=get(paste0("trace",k))$line$color[[1]], dash=get(paste0("trace",k))$line$dash[[1]]))
        }else{
          dont_plot=c(dont_plot,k)
        }
      }
      
      # set layout
      layout_comp = capture.output(
        for (l in 1:(hori*vert)){
          if (is.na(match(l, dont_plot))){
            if (l==1){
              cat(paste0("layout(p, polar=sub_plot",l,", "))
            }else if (l<=hori){
              cat(paste0("polar",l,"=sub_plot",l,", "))
            }else if (l<hori*vert){
              cat(paste0("polar",l,"=sub_plot",l,", "))
            }else{
              cat(paste0("polar",l,"=sub_plot",l,", showlegend=FALSE)"))
            }
          }
        })
      p; eval(parse(text=layout_comp))
    }else{
      cat("Sorry, this layout is not yet implemented in the function. Currently the options are either 2 variables shown horizontally and 1 shown vertically or 1 horizontally and 2 vertically.\n")
      cat("Usage: plotly_scatterpolar_multiplot(df, horizontal, vertical, cols2plot, print=TRUE) ->\n where df refers to the data.frame to plot, horizontal & vertical specify the column names to use as grouping variables,\n and cols2plot refers to the 2 columns of values to plot.\n")
      cat("Use the c(x, y) notation to specify multiple colums for horizontal and/or vertical and for the cols2plot columns.\n")
  }
  }
}

```


# Dataset

## Manipulation

```{r warning=FALSE, message=FALSE, error=FALSE}
df <- read.csv("all_data_NZE_Tongan_w_context_checked_7_March_2019_not_cut_checked_27_Apr.csv", sep=',', stringsAsFactors = F)

# remove empty column
df$X = NULL

df$tokenPooled <- factor(df$tokenPooled)
df$subject <- factor(df$subject)
df$sex <- factor(df$sex)
df$native_lg <- factor(df$native_lg)

df$playing_proficiency[df$playing_proficiency == "intermediate"] <- "amateur"
df$playing_proficiency <- factor(df$playing_proficiency, levels = c("amateur","semi-professional","professional"))

df$block <- factor(df$block)
df$point <- as.numeric(df$point)

df$note_intensity <- factor(df$note_intensity, levels = c("piano","mezzopiano","mezzoforte","forte"))
# remove fortissimo tokens
df = df[!(is.na(df$note_intensity) & df$activity=="music"),]
str(df)
```


## Two new datasets

### NZE

for NZE - note that we put the note intensity in place of preceeding and following context for notes.  This makes the models run more effectively

```{r warning=FALSE, message=FALSE, error=FALSE}
# using columns with IPA symbols
dfNZE <- subset(df,df$native_lg=="NZE")
dfNZE$tokenPooled <- factor(dfNZE$tokenPooled, levels = c("ɐː","ɐ","ɛ","ɵː","e","iː","ʉː","ʊ","oː","ɒ","ɘ","ə","ə#","Bb2","F3","Bb3","D4","F4"))

dfNZE$playing_proficiency <- as.factor(dfNZE$playing_proficiency)

# change NAs to NULL
# checked that only NAs are for speech tokens
# added removal of fortissimo tokens above!
dfNZE$note_intensity[is.na(dfNZE$note_intensity)] = "NULL"

# we're using speech_prec_pooled & speech_fol_pooled to create interactions below
# neither include NAs and both have NULL for speech tokens where there were no preceding/following sounds and intensity for the note tokens

levels(dfNZE$tokenPooled)
levels(dfNZE$playing_proficiency)
levels(dfNZE$note_intensity)
```


### Tongan

```{r}
dfTongan <- subset(df,df$native_lg=="Tongan")
dfTongan$tokenPooled <- factor(dfTongan$tokenPooled, levels = c("aː","a","eː","e","iː","i","uː","u","oː","o","Bb2","F3","Bb3","D4","F4"))

dfTongan$tokenPooled[dfTongan$tokenPooled == "aː"] = "a"
dfTongan$tokenPooled[dfTongan$tokenPooled == "eː"] = "e"
dfTongan$tokenPooled[dfTongan$tokenPooled == "iː"] = "i"
dfTongan$tokenPooled[dfTongan$tokenPooled == "uː"] = "u"
dfTongan$tokenPooled[dfTongan$tokenPooled == "oː"] = "o"

dfTongan$tokenPooled <- factor(dfTongan$tokenPooled)

dfTongan$playing_proficiency <- as.factor(dfTongan$playing_proficiency)

# we're using speech_prec_pooled & speech_fol_pooled to create interactions below
# neither include NAs and both have NULL for speech tokens where there were no preceding/following sounds and intensity for the note tokens

# speech_fol_pooled includes NAs that should be NULL
# checked that these NAs were only for speech tokens!
dfTongan$speech_prec_pooled[is.na(dfTongan$speech_prec_pooled)] = "NULL"
dfTongan$speech_fol_pooled[is.na(dfTongan$speech_fol_pooled)] = "NULL"

levels(dfTongan$tokenPooled)
levels(dfTongan$playing_proficiency)
levels(dfTongan$note_intensity)
```


## Tables to check structure

```{r warning=FALSE, message=FALSE, error=FALSE}
kable(table(dfNZE$tokenPooled,dfNZE$native_lg),format="html")
kable(table(dfNZE$note_intensity,dfNZE$native_lg),format="html")
kable(table(dfNZE$playing_proficiency,dfNZE$native_lg),format="html")
kable(table(dfNZE$age,dfNZE$native_lg),format="html")
kable(table(dfNZE$sex,dfNZE$native_lg),format="html")

kable(table(dfTongan$tokenPooled,dfTongan$native_lg),format="html")
kable(table(dfTongan$note_intensity,dfTongan$native_lg),format="html")
kable(table(dfTongan$playing_proficiency,dfTongan$native_lg),format="html")
kable(table(dfTongan$age,dfTongan$native_lg),format="html")
kable(table(dfTongan$sex,dfTongan$native_lg),format="html")
```


## Visualising the data by Vowel and by subject

Before running anything, we start by visualising the data

### NZE

Let's start with the NZE data. We see that speakers are variable in how they are producing the vowels (which is normal).

```{r warning=FALSE, message=FALSE, error=FALSE,fig.width=20, fig.height=20}
plotly_scatterpolar_multiplot(df=dfNZE, horizontal="subject", vertical="tokenPooled", cols2plot=c("theta_uncut_z","rho_uncut_z"))
```


### Tongan

Moving on to the Tongan data, we see again  that speakers are variable in how they are producing vowels (which is normal).

```{r warning=FALSE, message=FALSE, error=FALSE,fig.width=20, fig.height=20}
plotly_scatterpolar_multiplot(df=dfTongan, horizontal="subject", vertical="tokenPooled", cols2plot=c("theta_uncut_z","rho_uncut_z"))
```


### New variables

We will create two variables, one that combines token and preceeding context (either sound or note intensity), another that combines token and following context. This will allow us later on to use these instead of subject only to model the within subject variation with respect to the two other predictors (note and intensity)

```{r warning=FALSE, message=FALSE, error=FALSE}
dfNZE$subVowelInt <- interaction(dfNZE$subject, dfNZE$tokenPooled)
dfNZE$precSoundVowelInt <- interaction(dfNZE$speech_prec_pooled, dfNZE$tokenPooled)
dfNZE$follSoundVowelInt <- interaction(dfNZE$speech_fol_pooled, dfNZE$tokenPooled)

cat("\nNZE data\n")
levels(dfNZE$subVowelInt)
str(dfNZE$subVowelInt)
levels(dfNZE$precSoundVowelInt)
str(dfNZE$precSoundVowelInt)
levels(dfNZE$follSoundVowelInt)
str(dfNZE$follSoundVowelInt)

dfTongan$subVowelInt <- interaction(dfTongan$subject, dfTongan$tokenPooled)
dfTongan$precSoundVowelInt <- interaction(dfTongan$speech_prec_pooled, dfTongan$tokenPooled)
dfTongan$follSoundVowelInt <- interaction(dfTongan$speech_fol_pooled, dfTongan$tokenPooled)

cat("\nTongan data\n")
levels(dfTongan$subVowelInt)
str(dfTongan$subVowelInt)
levels(dfTongan$precSoundVowelInt)
str(dfTongan$precSoundVowelInt)
levels(dfTongan$follSoundVowelInt)
str(dfTongan$follSoundVowelInt)
```


# GAMM NZE

## Ordering predictors

We are intersted in the tongue position of musical notes in relation to the native language vowels. We create three new predictors. (*** Not sure if we should keep these yet)

```{r warning=FALSE, message=FALSE, error=FALSE}
dfNZE$tokenPooled.ord <- as.ordered(dfNZE$tokenPooled)
contrasts(dfNZE$tokenPooled.ord) <- "contr.treatment"
dfNZE$vowels_pooled.ord <- as.ordered(dfNZE$vowels_pooled)
contrasts(dfNZE$vowels_pooled.ord) <- "contr.treatment"
dfNZE$sex.ord <- as.ordered(dfNZE$sex)
contrasts(dfNZE$sex.ord) <- "contr.treatment"
dfNZE$playing_proficiency.ord <- as.ordered(dfNZE$playing_proficiency)
contrasts(dfNZE$playing_proficiency.ord) <- "contr.treatment"

dfTongan$tokenPooled.ord <- as.ordered(dfTongan$tokenPooled)
contrasts(dfTongan$tokenPooled.ord) <- "contr.treatment"
dfTongan$vowels_pooled.ord <- as.ordered(dfTongan$vowels_pooled)
contrasts(dfTongan$vowels_pooled.ord) <- "contr.treatment"
dfTongan$sex.ord <- as.ordered(dfTongan$sex)
contrasts(dfTongan$sex.ord) <- "contr.treatment"
dfTongan$playing_proficiency.ord <- as.ordered(dfTongan$playing_proficiency)
contrasts(dfTongan$playing_proficiency.ord) <- "contr.treatment"
```

We create a new variable (start) when Point of tongue == 1. Our dataset is already ordered by speaker, by token, by preceeding and following context, and by points of measurements.

```{r warning=FALSE, message=FALSE, error=FALSE}
dfNZE$start <- dfNZE$points==1
dfTongan$start <- dfTongan$points==1
```


## Running model with no random effects

We start by running a model with no random effects. Just to evaluate structure

### Model specification

```{r warning=FALSE, message=FALSE, error=FALSE}
if (run_models == TRUE){
  mdl.sys.time1 <- system.time(NZE.gam.noAR.noRandom <- bam(rho_uncut_z ~ tokenPooled.ord +
                         ## 1d smooths
                         s(theta_uncut_z, bs="cr", k=10) +
                         ## 1d smooths * factors
                         s(theta_uncut_z, k=10, bs="cr", by=tokenPooled.ord),
                         data=dfNZE, discrete=TRUE, nthreads=ncores))
  mdl.sys.time1
  # save model & model summary so they can be reloaded later
  saveRDS(NZE.gam.noAR.noRandom, paste0(output_dir,"/NZE.gam.noAR.noRandom.rds"))
  capture.output(summary(NZE.gam.noAR.noRandom),
                 file = paste0(output_dir,"/summary_NZE.gam.noAR.noRandom.txt"))

}else{
  # reload model from output_dir
  NZE.gam.noAR.noRandom = readRDS(paste0(output_dir,"/NZE.gam.noAR.noRandom.rds"))
}
```

### Summary

```{r}
summary(NZE.gam.noAR.noRandom)
```


## Models with random effects

Our second model includes random effects for subject. 

### Optimal models

#### Model specification

```{r warning=FALSE, message=FALSE, error=FALSE}
if (run_models == TRUE){
  mdl.sys.time2 <- system.time(NZE.gam.noAR.Mod1 <- bam(rho_uncut_z ~ tokenPooled.ord +
             ## 1d smooths
             s(theta_uncut_z, bs="cr", k=10) +
             ## 1d smooths * factors
             s(theta_uncut_z, k=10, bs="cr", by=tokenPooled.ord) +
             ## Factor smooths by subject, note and intensity
             s(theta_uncut_z, subVowelInt, bs="fs", k=10, m=1)+
             ## Factor smooths by preceding sound adjusted by vowel
             s(theta_uncut_z, precSoundVowelInt, bs="fs", k=10, m=1)+
             ## Factor smooths by following sound adjusted by vowel
             s(theta_uncut_z, follSoundVowelInt, bs="fs", k=10, m=1),
             data=dfNZE, discrete=TRUE, nthreads=ncores))
  mdl.sys.time2
  # save model & model summary so they can be reloaded later
  saveRDS(NZE.gam.noAR.Mod1, paste0(output_dir,"/NZE.gam.noAR.Mod1.rds"))
  capture.output(summary(NZE.gam.noAR.Mod1),
                 file = paste0(output_dir,"/summary_NZE.gam.noAR.Mod1.txt"))

}else{
  # reload model from output_dir
  NZE.gam.noAR.Mod1 = readRDS(paste0(output_dir,"/NZE.gam.noAR.Mod1.rds"))
}
```

#### Checking `k`

```{r warning=FALSE, message=FALSE, error=FALSE}
gam.check(NZE.gam.noAR.Mod1)
```

#### Summary

```{r warning=FALSE, message=FALSE, error=FALSE}
summary(NZE.gam.noAR.Mod1)
```



## Model with random effects and AR1 model

So far, our second model  that takes into account the random effect structure of by speaker, by note and by intensity accounted for 87% of the variance in the data. It showed some differences between the two languages in terms of how tongue contours are different depending on the note and its intensity.
We next need to check the autocorrelation in the residuals and acocunt for these.


### Checking ACF

#### ACF full

As we see below, the autocorrelation in the residuals is massive. We need to check whether this is on all predictors or on specific ones.

```{r warning=FALSE, message=FALSE, error=FALSE}
acf_resid(NZE.gam.noAR.Mod1, main = "Average ACF No.AR", cex.lab=1.5, cex.axis=1.5)
```

#### ACF by `theta_uncut_z`

There are some correlations between successive theta_uncut_z values that need to be taken into account (or not)

```{r warning=FALSE, message=FALSE, error=FALSE}
acf_resid(NZE.gam.noAR.Mod1, split_pred=list(dfNZE$theta_uncut_z), main = "Average ACF No.AR by theta_uncut_z", cex.lab=1.5, cex.axis=1.5)
```

#### ACF by `token`

There is massive correlations in the tokens that needs to be taken into account

```{r warning=FALSE, message=FALSE, error=FALSE}
acf_resid(NZE.gam.noAR.Mod1, split_pred=list(dfNZE$tokenPooled), main = "Average ACF No.AR by note", cex.lab=1.5, cex.axis=1.5)
```


## Running our final model 

This model takes into account the autocorrelations in the residuals

### Estimating `Rho`

We use the following to get an estimate of the `rho` to be included later on in our model

```{r}
rho_est <- start_value_rho(NZE.gam.noAR.Mod1)
rho_est
```


### Model specification

```{r warning=FALSE, message=FALSE, error=FALSE}
if (run_models == TRUE){
  mdl.sys.time3 <- system.time(NZE.gam.AR.Mod2 <- bam(rho_uncut_z ~ tokenPooled.ord +
             ## 1d smooths
             s(theta_uncut_z, bs="cr", k=10) +
             ## 1d smooths * factors
             s(theta_uncut_z, k=10, bs="cr", by=tokenPooled.ord) +
             ## Factor smooths by subject, note and intensity
             s(theta_uncut_z, subVowelInt, bs="fs", k=10, m=1)+
             ## Factor smooths by preceding sound adjusted by vowel
             s(theta_uncut_z, precSoundVowelInt, bs="fs", k=10, m=1)+
             ## Factor smooths by following sound adjusted by vowel
             s(theta_uncut_z, follSoundVowelInt, bs="fs", k=10, m=1),
             data=dfNZE,
             AR.start=dfNZE$start, rho=rho_est,
             discrete=TRUE, nthreads=ncores))
  mdl.sys.time3
  # save model & model summary so they can be reloaded later
  saveRDS(NZE.gam.AR.Mod2, paste0(output_dir,"/NZE.gam.AR.Mod2.rds"))
  capture.output(summary(NZE.gam.AR.Mod2),
                 file = paste0(output_dir,"/summary_NZE.gam.AR.Mod2.txt"))

}else{
  # reload model from output_dir
  NZE.gam.AR.Mod2 = readRDS(paste0(output_dir,"/NZE.gam.AR.Mod2.rds"))
}
```


### Checking ACF

#### ACF full

```{r warning=FALSE, message=FALSE, error=FALSE}
acf_resid(NZE.gam.AR.Mod2, main = "Average ACF AR", cex.lab=1.5, cex.axis=1.5)
```

#### ACF by `token`

```{r warning=FALSE, message=FALSE, error=FALSE}
acf_resid(NZE.gam.AR.Mod2, split_pred=list(dfNZE$tokenPooled), main = "Average ACF AR by note", cex.lab=1.5, cex.axis=1.5)
```

### Summary

```{r warning=FALSE, message=FALSE, error=FALSE}
summary(NZE.gam.AR.Mod2)
```


# GAMM TONGAN

This, in comparison, is the Tongan data.


## Running model with no random effects

### Model specification

```{r warning=FALSE, message=FALSE, error=FALSE}
if (run_models == TRUE){
  mdl.sys.time4 <- system.time(Tongan.gam.noAR.noRandom <- bam(rho_uncut_z ~ tokenPooled.ord +
                                                                ## 1d smooths
                                                                s(theta_uncut_z, bs="cr", k=10) +
                                                                ## 1d smooths * factors
                                                                s(theta_uncut_z, k=10, bs="cr",
                                                                  by=tokenPooled.ord), data=dfTongan,
                                                               discrete=TRUE, nthreads=ncores))
  mdl.sys.time4
  # save model & model summary so they can be reloaded later
  saveRDS(Tongan.gam.noAR.noRandom, paste0(output_dir,"/Tongan.gam.noAR.noRandom.rds"))
  capture.output(summary(Tongan.gam.noAR.noRandom), 
                 file = paste0(output_dir,"/summary_Tongan.gam.noAR.noRandom.txt"))

}else{
  # reload model from output_dir
  Tongan.gam.noAR.noRandom = readRDS(paste0(output_dir,"/Tongan.gam.noAR.noRandom.rds"))
}
```

### Summary

```{r}
summary(Tongan.gam.noAR.noRandom)
```

## Models with random effects

Our second model includes random effects for subject.

### Optimal models

#### Model specification

```{r warning=FALSE, message=FALSE, error=FALSE}
if (run_models == TRUE){
  mdl.sys.time5 <- system.time(Tongan.gam.noAR.Mod1 <- bam(rho_uncut_z ~ tokenPooled.ord +
                                 ## 1d smooths
                                 s(theta_uncut_z, bs="cr", k=10) +
                                 ## 1d smooths * factors
                                 s(theta_uncut_z, k=10, bs="cr", by=tokenPooled.ord) +
                                 ## Factor smooths by subject, note and intensity
                                 s(theta_uncut_z, subVowelInt, bs="fs", k=10, m=1)+
                                 ## Factor smooths by preceding sound adjusted by vowel
                                 s(theta_uncut_z, precSoundVowelInt, bs="fs", k=10, m=1)+
                                 ## Factor smooths by following sound adjusted by vowel
                                 s(theta_uncut_z, follSoundVowelInt, bs="fs", k=10, m=1),
                               data=dfTongan, discrete=TRUE, nthreads=ncores))
  mdl.sys.time5
  # save model & model summary so they can be reloaded later
  saveRDS(Tongan.gam.noAR.Mod1, paste0(output_dir,"/Tongan.gam.noAR.Mod1.rds"))
  capture.output(summary(Tongan.gam.noAR.Mod1), 
                 file = paste0(output_dir,"/summary_Tongan.gam.noAR.Mod1.txt"))

}else{
  # reload model from output_dir
  Tongan.gam.noAR.Mod1 = readRDS(paste0(output_dir,"/Tongan.gam.noAR.Mod1.rds"))
}
```


#### Checking `k`


```{r warning=FALSE, message=FALSE, error=FALSE}
gam.check(Tongan.gam.noAR.Mod1)
```

#### Summary

```{r warning=FALSE, message=FALSE, error=FALSE}
summary(Tongan.gam.noAR.Mod1)
```


## Model with random effects and AR1 model

So far, our second model that takes into account the random effect structure of by speaker, by note and by intensity accounted for 90% of the variance in the data. It showed some differences between the two languages in terms of how tongue contours are different depending on the note and its intensity.
We next need to check the autocorrelation in the residuals and acocunt for these.

### Checking ACF

#### ACF full

As we see below, the autocorrelation in the residuals is massive. We need to check whether this is on all predictors or on specific ones.

```{r warning=FALSE, message=FALSE, error=FALSE}
acf_resid(Tongan.gam.noAR.Mod1, main = "Average ACF No.AR", cex.lab=1.5, cex.axis=1.5)
```

#### ACF by `theta_uncut_z`

There is some correlations between successive theta_uncut_z that needs to be taken into account (or not)

```{r warning=FALSE, message=FALSE, error=FALSE}
acf_resid(Tongan.gam.noAR.Mod1, split_pred=list(dfTongan$theta_uncut_z),main = "Average ACF No.AR by theta_uncut_z", cex.lab=1.5, cex.axis=1.5)
```

#### ACF by `token`

There is massive correlations in the notes that needs to be taken into account

```{r warning=FALSE, message=FALSE, error=FALSE}
acf_resid(Tongan.gam.noAR.Mod1, split_pred=list(dfTongan$tokenPooled), main = "Average ACF No.AR by note", cex.lab=1.5, cex.axis=1.5)
```


## Running our final model 

This model takes into account the autocorrelations in the residuals

### Estimating `Rho`

We use the following to get an estimate of the `rho` to be included later on in our model

```{r}
rho_est <- start_value_rho(Tongan.gam.noAR.Mod1)
rho_est
```

### Model specification

```{r warning=FALSE, message=FALSE, error=FALSE}
if (run_models == TRUE){
  mdl.sys.time6 <- system.time(Tongan.gam.AR.Mod2 <- bam(rho_uncut_z ~ tokenPooled.ord +
                               ## 1d smooths
                               s(theta_uncut_z, bs="cr", k=10) +
                               ## 1d smooths * factors
                               s(theta_uncut_z, k=10, bs="cr", by=tokenPooled.ord) +
                               ## Factor smooths by subject, note and intensity
                               s(theta_uncut_z, subVowelInt, bs="fs", k=10, m=1)+
                               ## Factor smooths by preceding sound and vowel adjusted by language
                               s(theta_uncut_z, precSoundVowelInt, bs="fs", k=10, m=1)+
                               ## Factor smooths by following sound and vowel adjusted by language
                               s(theta_uncut_z, follSoundVowelInt, bs="fs", k=10, m=1),
                             data=dfTongan, AR.start=dfTongan$start, rho=rho_est,
                             discrete=TRUE, nthreads=ncores))
  mdl.sys.time6
  # save model & model summary so they can be reloaded later
  saveRDS(Tongan.gam.AR.Mod2, paste0(output_dir,"/Tongan.gam.AR.Mod2.rds"))
  capture.output(summary(Tongan.gam.AR.Mod2), 
                 file = paste0(output_dir,"/summary_Tongan.gam.AR.Mod2.txt"))

}else{
  # reload model from output_dir
  Tongan.gam.AR.Mod2 = readRDS(paste0(output_dir,"/Tongan.gam.AR.Mod2.rds"))
}
```


### Checking ACF

#### ACF full

```{r warning=FALSE, message=FALSE, error=FALSE}
acf_resid(Tongan.gam.AR.Mod2, main = "Average ACF AR", cex.lab=1.5, cex.axis=1.5)
```

#### ACF by `token`

```{r warning=FALSE, message=FALSE, error=FALSE}
acf_resid(Tongan.gam.AR.Mod2, split_pred=list(dfTongan$tokenPooled), main = "Average ACF AR by token", cex.lab=1.5, cex.axis=1.5)
```

### Summary

```{r warning=FALSE, message=FALSE, error=FALSE}
summary(Tongan.gam.AR.Mod2)
```

